{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Result.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTduCIdXcuH0"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import csv"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS64vs8-cTCb"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znf3pkkBcWhS",
        "outputId": "ff0fb75c-a1cf-4acb-efea-e1e5e97bc1e3"
      },
      "source": [
        "# Run this cell when computing results for Validation Data\r\n",
        "\r\n",
        "file = '/content/Hostile_Validate.xlsx'\r\n",
        "test_df = pd.read_excel(file)\r\n",
        "\r\n",
        "# Data Preparation into Pandas Dataframe for Model Input\r\n",
        "\r\n",
        "def get_data(a):\r\n",
        "  Unique_ID = list(a['Unique ID'])\r\n",
        "  sentence = list(a['Post'])\r\n",
        "\r\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence}\r\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence'])\r\n",
        "  return df\r\n",
        "\r\n",
        "test_data  = get_data(test_df)\r\n",
        "\r\n",
        "print(test_data[0:3])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   UID                                           sentence\n",
            "0    2  भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं ...\n",
            "1    6  हॉन्ग कॉन्ग में एक व्यक्ति में दोबारा कोरोना क...\n",
            "2    8  अद्भुत   जो वामपंथी कहते है कि महाभारत का युद्...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnnr9IQrZgdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c212c7ff-5e70-460a-cb8d-83717b315696"
      },
      "source": [
        "# Run this cell when computing results for Test Data\n",
        "\n",
        "file = '/content/Hostile_Hindi_Test.xlsx'\n",
        "test_df = pd.read_excel(file, names = ['Unique ID','Post'])\n",
        "\n",
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence'])\n",
        "  return df\n",
        "\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(test_data[0:3])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   UID                                           sentence\n",
            "0    1  कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...\n",
            "1    3  कोई भी कांग्रेसी  ऊंची छत पर  रेलवे लाइन पर  ऊ...\n",
            "2    4  अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um2aYOzrbabh"
      },
      "source": [
        "# Hostile ID Collection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHN-feglaTQS"
      },
      "source": [
        "# Collecting Hostile IDs from Validation Data\n",
        "\n",
        "data = test_data\n",
        "\n",
        "hos_ids = []\n",
        "for i in range(len(data)):\n",
        "  id = data['UID'][i]\n",
        "  hos_ids.append(id)\n",
        "\n",
        "hos_ids = np.array(hos_ids, dtype=np.int)\n",
        "np.save('Hostile_ID.npy',hos_ids)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1XcSlsPbixS"
      },
      "source": [
        "# Predicted Labels Loading (Fake, Hate, Offensive, Defamation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGYARfJRbKCB"
      },
      "source": [
        "# Loading previously obtained Predicted Labels and Hostile IDs from Previous Cell\n",
        "\n",
        "bin_lab = np.load('/content/Test_Labels_Coarse.npy', allow_pickle=True)\n",
        "d_lab = np.load('/content/Pred_Defamation_Label.npy', allow_pickle=True)\n",
        "f_lab = np.load('/content/Pred_Fake_Label.npy', allow_pickle=True)\n",
        "h_lab = np.load('/content/Pred_Hate_Label.npy', allow_pickle=True)\n",
        "o_lab = np.load('/content/Pred_Offensive_Label.npy', allow_pickle=True)\n",
        "hos_ids = np.load('/content/Hostile_ID.npy', allow_pickle=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0eSzzsZcAPI"
      },
      "source": [
        "# Merging Labels to Asses Performance measurement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK32tt7ceBlu"
      },
      "source": [
        "# Run Cell when Evaluating Validation Data\r\n",
        "\r\n",
        "# Merging Predicted labels into a single numpy array\r\n",
        "# Reference: [non_hostile,defamation,fake,hate,offensive]\r\n",
        "\r\n",
        "predicted_labels = []\r\n",
        "\r\n",
        "count = 0\r\n",
        "\r\n",
        "for i in range(1,812):         # Rectified Line (Error: ID Mismatch)\r\n",
        "  row = []\r\n",
        "  if i not in hos_ids:\r\n",
        "    row.append([1,0,0,0,0])\r\n",
        "  else:\r\n",
        "    alt_row = [0,0,0,0,0]\r\n",
        "    if d_lab[count]==1:\r\n",
        "      alt_row[1] = 1\r\n",
        "    if f_lab[count]==1:\r\n",
        "      alt_row[2] = 1\r\n",
        "    if h_lab[count]==1:\r\n",
        "      alt_row[3] = 1\r\n",
        "    if o_lab[count]==1:\r\n",
        "      alt_row[4] = 1\r\n",
        "    count += 1\r\n",
        "    row.append(alt_row)\r\n",
        "  predicted_labels.append(row)\r\n",
        "\r\n",
        "pred_lab = np.reshape(np.array(predicted_labels),(811,5)) # Final Predicted Labels\r\n",
        "np.save('Pred_Validation_labels.npy',pred_lab)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5CH0c26brAh"
      },
      "source": [
        "# Run Cell when Evaluating Test Data\n",
        "\n",
        "# Merging Predicted labels into a single numpy array\n",
        "# Reference: [non_hostile,defamation,fake,hate,offensive]\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "'''\n",
        "for i in range(1653):           # ERROR LINE: where mapping got mismatched (Wrong Test File Submitted in Competition)\n",
        "'''\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(1,1654):         # Rectified Line (Error: ID Mismatch)\n",
        "  row = []\n",
        "  if i not in hos_ids:\n",
        "    row.append([1,0,0,0,0])\n",
        "  else:\n",
        "    alt_row = [0,0,0,0,0]\n",
        "    if d_lab[count]==1:\n",
        "      alt_row[1] = 1\n",
        "    if f_lab[count]==1:\n",
        "      alt_row[2] = 1\n",
        "    if h_lab[count]==1:\n",
        "      alt_row[3] = 1\n",
        "    if o_lab[count]==1:\n",
        "      alt_row[4] = 1\n",
        "    count += 1\n",
        "    row.append(alt_row)\n",
        "  predicted_labels.append(row)\n",
        "\n",
        "pred_lab = np.reshape(np.array(predicted_labels),(1653,5)) # Final Predicted Labels\n",
        "np.save('Pred_Test_labels.npy',pred_lab)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxGuj7BfDnRi"
      },
      "source": [
        "# For Validation Data Results (Run this if Loading Validation Dataset in Data Loading Cell)\r\n",
        "y_true = np.load('/content/True_Validation_Labels.npy', allow_pickle=True)       # Released by Organizers\r\n",
        "y_pred = np.load('/content/Pred_Validation_labels.npy', allow_pickle=True)       # Created from our Models"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfok1L51b_W4"
      },
      "source": [
        "# For Test Data Results (Run this if Loading Test Dataset in Data Loading Cell)\n",
        "y_pred = np.load('/content/Pred_Test_labels.npy', allow_pickle=True)             # Created from our Models"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xksjw8kCclP4"
      },
      "source": [
        "# Creating Final Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLC1RLkacgLh"
      },
      "source": [
        "# Reference: [non_hostile,defamation,fake,hate,offensive]\n",
        "labels = []\n",
        "\n",
        "for i in range(y_pred.shape[0]):\n",
        "  lab_text = []\n",
        "  idx = np.argwhere(y_pred[i]>0)\n",
        "  idx = idx.reshape(idx.shape[0],)\n",
        "  if len(idx)==0:\n",
        "    lab_text.append('defamation')\n",
        "  else:\n",
        "    for j in idx:\n",
        "      if j==0:\n",
        "        lab_text.append('non-hostile')\n",
        "      if j==1:\n",
        "        lab_text.append('defamation')\n",
        "      if j==2:\n",
        "        lab_text.append('fake')\n",
        "      if j==3:\n",
        "        lab_text.append('hate')\n",
        "      if j==4:\n",
        "        lab_text.append('offensive')\n",
        "  labels.append(lab_text)\n",
        "\n",
        "\n",
        "def final_submission(label_list):\n",
        "  data = []\n",
        "  titles = ['Unique ID','Labels Set']\n",
        "  data.append(titles)\n",
        "  for i in range(len(label_list)):\n",
        "    row = []\n",
        "    row.append(i+1)\n",
        "    lab_text = ''\n",
        "    for j in range(len(label_list[i])):\n",
        "      lab_text += str(label_list[i][j])+','\n",
        "    lab_text = lab_text[:-1]+''\n",
        "    row.append(str(lab_text))\n",
        "    data.append(row)\n",
        "\n",
        "  file1 = \"Results.csv\"\n",
        "  with open(file1, 'w') as csvfile:  \n",
        "    csvwriter = csv.writer(csvfile)   \n",
        "    csvwriter.writerows(data)\n",
        "\n",
        "final_submission(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvTz_EPgMsHz"
      },
      "source": [
        "# Final Test Dataset Result (Official Script)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJcG-3hReZ_J",
        "outputId": "b0d791dc-e3f7-45f9-fff8-c7fce37878c7"
      },
      "source": [
        "### Order of Labels --> [Hostile,defamation,fake,hate,offensive,non-hostile]\r\n",
        "### An example      --> [1,0,1,1,0,0]\r\n",
        "\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def preprocess(df):\r\n",
        "    \r\n",
        "    df = df.dropna()\r\n",
        "    \r\n",
        "    df.insert(len(df.columns)-1,'Hostile', np.zeros(len(df),dtype=int))\r\n",
        "    df.insert(len(df.columns)-1,'Defamation', np.zeros(len(df),dtype=int))\r\n",
        "    df.insert(len(df.columns)-1,'Fake', np.zeros(len(df),dtype=int))\r\n",
        "    df.insert(len(df.columns)-1,'Hate', np.zeros(len(df),dtype=int))\r\n",
        "    df.insert(len(df.columns)-1,'Offensive', np.zeros(len(df),dtype=int))\r\n",
        "    df.insert(len(df.columns)-1,'Non-Hostile', np.zeros(len(df),dtype=int))    \r\n",
        "    \r\n",
        "    for i in range(len(df)):\r\n",
        "        text = df['Labels Set'][i]\r\n",
        "        text = text.lower()\r\n",
        "        text = text.replace('\\n',\"\")\r\n",
        "        text = text.replace('\"',\"\")\r\n",
        "        text = text.replace(\" \",\"\")\r\n",
        "        text = text.split(',')\r\n",
        "\r\n",
        "\r\n",
        "        for word in text:\r\n",
        "            if word == 'defamation':\r\n",
        "                df.at[i,'Hostile']    = 1\r\n",
        "                df.at[i,'Defamation'] = 1\r\n",
        "    \r\n",
        "            if word == 'fake':\r\n",
        "                df.at[i,'Hostile']    = 1\r\n",
        "                df.at[i,'Fake'] = 1\r\n",
        "    \r\n",
        "            if word == 'hate':\r\n",
        "                df.at[i,'Hostile']    = 1\r\n",
        "                df.at[i,'Hate'] = 1\r\n",
        "    \r\n",
        "            if word == 'offensive':\r\n",
        "                df.at[i,'Hostile']    = 1\r\n",
        "                df.at[i,'Offensive'] = 1\r\n",
        "    \r\n",
        "            if word == 'non-hostile' and df['Hostile'][i]==0:\r\n",
        "                df.at[i,'Hostile']    = 0\r\n",
        "                df.at[i,'Non-Hostile'] = 1\r\n",
        "\r\n",
        "    return df \r\n",
        "  \r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_scores(y_true, y_pred):\r\n",
        "    \r\n",
        "    hostility_true = y_true['Hostile']\r\n",
        "    hostility_pred = y_pred['Hostile']\r\n",
        "    \r\n",
        "    hostility_f1 = f1_score(y_true=hostility_true, y_pred=hostility_pred, average='weighted')\r\n",
        "    \r\n",
        "    \r\n",
        "    nh_indexes = y_true[y_true['Hostile']==0].index\r\n",
        "    y_true = y_true.drop(nh_indexes)\r\n",
        "    y_true = y_true.reset_index(drop=True)\r\n",
        "    \r\n",
        "    y_pred = y_pred.drop(nh_indexes)\r\n",
        "    y_pred = y_pred.reset_index(drop=True)\r\n",
        "    \r\n",
        "    \r\n",
        "    fine_true = y_true[['Defamation','Fake','Hate','Offensive']]\r\n",
        "    fine_pred = y_pred[['Defamation','Fake','Hate','Offensive']]\r\n",
        "    \r\n",
        "    \r\n",
        "    fine_f1          = f1_score(y_true=fine_true, y_pred=fine_pred, average=None)\r\n",
        "    defame_f1        = fine_f1[0]\r\n",
        "    fake_f1          = fine_f1[1]\r\n",
        "    hate_f1          = fine_f1[2]\r\n",
        "    offensive_f1     = fine_f1[3]\r\n",
        "    weighted_fine_f1 = f1_score(y_true=fine_true, y_pred=fine_pred, average='weighted')\r\n",
        "\r\n",
        "    return [hostility_f1, defame_f1, fake_f1, hate_f1, offensive_f1, weighted_fine_f1]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "ground_truth_path      = \"/content/Ground_Truth.csv\"                            # Load Test or Validation Ground Truth\r\n",
        "submission_file_path   = \"/content/Results.csv\"                                 # Load Test or Validation Submission.csv\r\n",
        " \r\n",
        "\r\n",
        "try:  \r\n",
        "    y_true = pd.read_csv(ground_truth_path)\r\n",
        "    y_pred = pd.read_csv(submission_file_path)\r\n",
        "    \r\n",
        "    y_true = preprocess(y_true)\r\n",
        "    y_pred = preprocess(y_pred)\r\n",
        "    \r\n",
        "    team_score = get_scores(y_true,y_pred)\r\n",
        "    \r\n",
        "    \r\n",
        "except:\r\n",
        "    team_score = [0,0,0,0,0,0]\r\n",
        "    \r\n",
        "        \r\n",
        "print(\"Coarse Grained F1-score: \", team_score[0])\r\n",
        "print(\"Defamation F1-score:     \", team_score[1])\r\n",
        "print(\"Fake F1-score:           \", team_score[2])\r\n",
        "print(\"Hate F1-score:           \", team_score[3])\r\n",
        "print(\"Offensive F1-score:      \", team_score[4])\r\n",
        "print(\"Fine Grained F1-score:   \", team_score[5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coarse Grained F1-score:  0.9059207129656424\n",
            "Defamation F1-score:      0.3937007874015748\n",
            "Fake F1-score:            0.6330935251798562\n",
            "Hate F1-score:            0.4724061810154525\n",
            "Offensive F1-score:       0.5555555555555556\n",
            "Fine Grained F1-score:    0.5336803174740802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYIgX5OQhfAZ"
      },
      "source": [
        "# Important Note\r\n",
        "\r\n",
        "In the Test Submission Phase, we submitted the same file but the IDs got mismatched (due to the wrong oneline marked in the previous cell as ERROR LINE)\r\n",
        "We rectified this in the post test phase. (Next line after ERROR LINE)"
      ]
    }
  ]
}