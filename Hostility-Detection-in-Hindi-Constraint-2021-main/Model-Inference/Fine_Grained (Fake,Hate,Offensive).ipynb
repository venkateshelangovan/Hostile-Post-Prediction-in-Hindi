{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Fine_Grained_One_vs_Rest_Approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d41bacf85be247e0b6bf0be16fde5a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_994e1f6e734d40c384cdb7e6c795290b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_287aebe76ec54b008926cddedb01abca",
              "IPY_MODEL_c7385022e9dd43f08ebc833aeb5b43d6"
            ]
          }
        },
        "994e1f6e734d40c384cdb7e6c795290b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "287aebe76ec54b008926cddedb01abca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b7371f8033349b69d7e5ba716ad83ad",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c06ab3e75f5d492b83625d59f6bbd98a"
          }
        },
        "c7385022e9dd43f08ebc833aeb5b43d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8df063fca0f84c709b710064c2e6549f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 5.84kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65814b9297ee43a4afc62684ed042a6d"
          }
        },
        "4b7371f8033349b69d7e5ba716ad83ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c06ab3e75f5d492b83625d59f6bbd98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8df063fca0f84c709b710064c2e6549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65814b9297ee43a4afc62684ed042a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3b07f50e5c34f8687f22b512e0e39e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1451a3dc2cf477992277539d93b243d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cef7869fe03499eac671e3dc456cb43",
              "IPY_MODEL_60bbb694e84245e9becb34085268eff0"
            ]
          }
        },
        "d1451a3dc2cf477992277539d93b243d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cef7869fe03499eac671e3dc456cb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6585aa670ad64e04bb0b08e5771f1ce3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_700d3f553ffa451abb55573f360ef5b9"
          }
        },
        "60bbb694e84245e9becb34085268eff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e609f78901d4795af85603d3298ecd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 14.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfce00101e454c0ca042a334bbaace71"
          }
        },
        "6585aa670ad64e04bb0b08e5771f1ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "700d3f553ffa451abb55573f360ef5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e609f78901d4795af85603d3298ecd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfce00101e454c0ca042a334bbaace71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2rj4jmOvJL"
      },
      "source": [
        "# For Fake, Hate, Offensive Datasets\n",
        "\n",
        "# Code Objective:\n",
        "\n",
        "*   mBERT Model for Fine Grained Evaluation\n",
        "*   Constructing Problem from Multilabel Classification to independent Binary Classification\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dWCw-Y5PuXQ"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMlDjs63TBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed830f8b-4904-422f-c03e-8df2cdbd2e96"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 12.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 58.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=95f221286f8af0b3321880dc6da638bd11a6de2fdab24d442e8728f23a61bb67\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ppFOaeJxHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba2de47-177d-4074-c557-5df9ccca24c5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import glue_compute_metrics\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, XLMRobertaForSequenceClassification\n",
        "\n",
        "print(\"GPU Torch Available = {}\".format(torch.cuda.is_available()))\n",
        "print(\"Torch Version = {}\".format(torch.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Torch Available = True\n",
            "Torch Version = 1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiO16rxYP0lF"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNpz82GUY8rk"
      },
      "source": [
        "# Validation Data Loading (Only Run when Evaluation of Validation Data)\r\n",
        "\r\n",
        "'''\r\n",
        "Loading Dataset for Finegrained Multilabel Evaluation which has been transformed\r\n",
        "as multiple independent binary classification (One vs Rest Approach)\r\n",
        "'''\r\n",
        "\r\n",
        "dataset = 'hate'                            # Choosing Dataset and Finetuned Model to Load (fake, offensive, hate)\r\n",
        "\r\n",
        "# Test Data\r\n",
        "file = '/content/Hostile_Validate.xlsx'\r\n",
        "test_df = pd.read_excel(file)\r\n",
        "train_df = test_df                          # Dummy Train dataframe (Unused)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlZhZHC9YG4a"
      },
      "source": [
        "# Test Data Loading (Only Run when Evaluation of Test Data)\n",
        "\n",
        "'''\n",
        "Loading Dataset for Finegrained Multilabel Evaluation which has been transformed\n",
        "as multiple independent binary classification (One vs Rest Approach)\n",
        "'''\n",
        "\n",
        "dataset = 'offensive'                            # Choosing Dataset and Finetuned Model to Load (fake, offensive, hate)\n",
        "\n",
        "# Test Data\n",
        "file = '/content/Hostile_Hindi_Test.xlsx'\n",
        "test_df = pd.read_excel(file, names = ['Unique ID','Post'])\n",
        "train_df = test_df                          # Dummy Train dataframe (Unused)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPD7q2_YM55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910ee9ce-5829-49ee-e3ca-f58654081a49"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  \n",
        "  # Appending dummy labels\n",
        "  label = []\n",
        "  for i in Unique_ID:\n",
        "    label.append(0)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "test_data = get_data(test_df)\n",
        "train_data = test_data                      # Dummy Train dataframe (Unused)\n",
        "\n",
        "print(test_data[0:3])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   UID                                           sentence  label\n",
            "0    1  कीस की को रोजगार चाहिए फिर नहीं कहना रोजगार नह...      0\n",
            "1    3  कोई भी कांग्रेसी  ऊंची छत पर  रेलवे लाइन पर  ऊ...      0\n",
            "2    4  अंडरवर्ल्ड डॉन छोटा राजन के भाई को बीजेपी द्वा...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-LBlN9xStzh"
      },
      "source": [
        "# Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ALqUM9f5Qnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "d41bacf85be247e0b6bf0be16fde5a7d",
            "994e1f6e734d40c384cdb7e6c795290b",
            "287aebe76ec54b008926cddedb01abca",
            "c7385022e9dd43f08ebc833aeb5b43d6",
            "4b7371f8033349b69d7e5ba716ad83ad",
            "c06ab3e75f5d492b83625d59f6bbd98a",
            "8df063fca0f84c709b710064c2e6549f",
            "65814b9297ee43a4afc62684ed042a6d",
            "d3b07f50e5c34f8687f22b512e0e39e4",
            "d1451a3dc2cf477992277539d93b243d",
            "7cef7869fe03499eac671e3dc456cb43",
            "60bbb694e84245e9becb34085268eff0",
            "6585aa670ad64e04bb0b08e5771f1ce3",
            "700d3f553ffa451abb55573f360ef5b9",
            "5e609f78901d4795af85603d3298ecd3",
            "dfce00101e454c0ca042a334bbaace71"
          ]
        },
        "outputId": "eccb2f99-3073-41a0-abbf-3334b69178ab"
      },
      "source": [
        "model_name = 'Bert'\n",
        "\n",
        "if (model_name == 'Bert'):\n",
        "  # Bert Parameters\n",
        "  config = BertConfig.from_pretrained('bert-base-multilingual-cased',num_labels=2)\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "  model = BertForSequenceClassification(config)\n",
        "  print('BERT Model Loaded')\n",
        "else:\n",
        "  print('Choose correct Model')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d41bacf85be247e0b6bf0be16fde5a7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3b07f50e5c34f8687f22b512e0e39e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BERT Model Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xsy7ghkSvyf"
      },
      "source": [
        "# Data Preparation for Model Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0ATRkF5LEx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.sentence = dataframe.sentence\n",
        "        self.targets = self.data.label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.sentence[index])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(sentence1,\n",
        "                                            truncation=True,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=self.max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {'input_ids': torch.tensor(ids, dtype=torch.long),\n",
        "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "               }"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDx-QxmX5Muc"
      },
      "source": [
        "# Dataset for Input into Model\n",
        "MAX_LEN = 128                                                 # Max Sequence Length\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN)  # Training Set\n",
        "testing_set = CustomDataset(test_data, tokenizer, MAX_LEN)    # Validation Set"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnQH2cqlTRoU"
      },
      "source": [
        "# Training and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ia34HohXuSU"
      },
      "source": [
        "# Device Mapping Select (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(output_dir=\"./models/model_name\",\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  per_device_train_batch_size=28,\n",
        "                                  per_device_eval_batch_size=28,\n",
        "                                  num_train_epochs=20,\n",
        "                                  logging_steps=100,\n",
        "                                  logging_first_step=True,\n",
        "                                  save_steps=0,\n",
        "                                  evaluation_strategy ='epoch')\n",
        "\n",
        "# Metric for Performance Evaluation\n",
        "def compute_metrics(p):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return glue_compute_metrics(\"mnli\", preds, p.label_ids)\n",
        "\n",
        "# Trainer for training Model\n",
        "trainer = Trainer(model = model,\n",
        "                  args = training_args,\n",
        "                  train_dataset = training_set,\n",
        "                  eval_dataset = testing_set,\n",
        "                  compute_metrics = compute_metrics)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOmRXdAzZnEI",
        "outputId": "44c86f27-e8e8-4f44-c439-b6250ad78b6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rLxbywe7ol7",
        "outputId": "37af6189-74d1-49dc-b464-58bcad8e4881"
      },
      "source": [
        "# Pretrained Model Load\r\n",
        "model_path = '/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/BERT_state_dict_' + dataset + '.pth'\r\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v84hu3rWXzz8"
      },
      "source": [
        "# Once model is loaded from previous cell, no need to run this cell\n",
        "\n",
        "\n",
        "# Training Model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluation of Model on Validation Data\n",
        "trainer.evaluate(testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOOA69dLXLUk"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpV2-snhjnR4"
      },
      "source": [
        "'''\n",
        "Load Model, predict on validation or test data and get labels for each dataset\n",
        "For 3 different datasets (Fake, Hate, Offensive) \n",
        "we get 3 output numpy array of labels. \n",
        "'''\n",
        "\n",
        "Label_Name = 'Offensive'   # Choose from (Fake, Offensive, Hate)\n",
        "\n",
        "\n",
        "# Prediction\n",
        "def prepare_features(seq_1, max_seq_length = 128, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
        "\n",
        "\n",
        "def predict(text):\n",
        "  model.eval()\n",
        "  input_feature, _ = prepare_features(text)\n",
        "  if torch.cuda.is_available():\n",
        "    input_feature = input_feature.cuda()\n",
        "  output = model(input_feature)[0]\n",
        "  _, pred_label = torch.max(output.data, 1)\n",
        "  prediction = pred_label[0].item()\n",
        "  if (prediction == 0):\n",
        "    return 'non_offensive',0\n",
        "  else:\n",
        "    return 'offensive',1\n",
        "\n",
        "data = test_data\n",
        "\n",
        "pred = []\n",
        "pred_lab = []\n",
        "for i in range(len(data)):\n",
        "  text = data['sentence'][i]\n",
        "  pred_text , pred_label = predict(text)\n",
        "  pred.append(pred_text)\n",
        "  pred_lab.append(pred_label)\n",
        "\n",
        "pred_lab = np.array(pred_lab, dtype=np.float)\n",
        "np.save('Pred_' + Label_Name + '_Label.npy',pred_lab)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}