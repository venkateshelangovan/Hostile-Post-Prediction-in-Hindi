{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coarse_Grained_Finetune (mBERT).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BzqiIMgJrq-w"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZKTUvZ-i9uS"
      },
      "source": [
        "SEED = 42\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install bert-tensorflow==1.0.1\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkOu6hxrK1vW"
      },
      "source": [
        "file = '/content/bin_train.xlsx'      \r\n",
        "train_df = pd.read_excel(file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbM7v11FH9FQ"
      },
      "source": [
        "# Loading Validation Data (Run when evaluating for Validation Data)\r\n",
        "file = '/content/Validation.xlsx'       # Cleaned Validation Data (Obtained After Preprocessing the Original Validation Data from Organizers)\r\n",
        "test_df = pd.read_excel(file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgO9kOSEan55"
      },
      "source": [
        "# Loading Test Data (Run when evaluating for Test Data)\r\n",
        "file = '/content/Hindi_Test.xlsx'       # Cleaned Test Data (Obtained After Preprocessing the Original Test Data from Organizers)\r\n",
        "test_df = pd.read_excel(file,names=['Row','Unique ID','Post'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Bn7ACWjHG_"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "\n",
        "  # Appending Dummy Labels as Labels are not needed\n",
        "  label = []\n",
        "  for i in Unique_ID:\n",
        "    label.append(0)    \n",
        "\n",
        "  \n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "train_data = get_data(train_df)\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYT3uHNMjHJ3"
      },
      "source": [
        "# Loading mBERT Model\n",
        "\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip\n",
        "!unzip multilingual_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCw7XyUpjHSd"
      },
      "source": [
        "label_list = [0,1]\n",
        "\n",
        "train_InputExamples = train_data.apply(lambda x: bert.run_classifier.InputExample(guid = x['UID'],\n",
        "                                                                                  text_a = x['sentence'],  \n",
        "                                                                                  label = x['label']), axis = 1)\n",
        "\n",
        "test_InputExamples = test_data.apply(lambda x: bert.run_classifier.InputExample(guid = x['UID'],\n",
        "                                                                                text_a = x['sentence'],  \n",
        "                                                                                label = x['label']), axis = 1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6-s5Q4jHYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec930bd-3919-480c-f7fb-6e6b1c125fd7"
      },
      "source": [
        "vocab_file = \"multilingual_L-12_H-768_A-12/vocab.txt\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n",
        "# Check Tokenizer\n",
        "print(tokenizer.tokenize(\"धीरे\"))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ध', '##ीर']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9inljAfjHex"
      },
      "source": [
        "# Convert train and test features to InputFeatures that BERT understands.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXQFANDRCxKZ"
      },
      "source": [
        "# Binary Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-0dlaxmjHdM"
      },
      "source": [
        "# Binary Classification Model\n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids, labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(config=bert_config,\n",
        "                                                 is_training=is_training,\n",
        "                                                 input_ids=input_ids,\n",
        "                                                 input_mask=input_mask,\n",
        "                                                 token_type_ids=segment_ids,\n",
        "                                                 use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "  #Sizes\n",
        "  output_layer = model.get_pooled_output()\n",
        "  pooled_output = model.get_pooled_output()\n",
        "  token_output = model.get_sequence_output()\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  #Trainable Parameters\n",
        "  output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "  output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)  # dropout = 0.1 \n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels,output_layer,token_output,pooled_output)\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate, num_train_steps, num_warmup_steps, use_tpu, use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels,hidden_context,token_outputs,pooled_output) = create_model(bert_config, \n",
        "                                                                                                         is_training, \n",
        "                                                                                                         input_ids, \n",
        "                                                                                                         input_mask, \n",
        "                                                                                                         segment_ids, \n",
        "                                                                                                         label_ids,\n",
        "                                                                                                         num_labels, \n",
        "                                                                                                         use_one_hot_embeddings)\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    output_spec = None\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        return {\"eval_accuracy\": accuracy, \"eval_loss\": loss}\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, \n",
        "                                               predictions={\"probabilities\": probabilities,\n",
        "                                                            \"labels\": predicted_labels, \n",
        "                                                            \"hidden_context\": hidden_context,\n",
        "                                                            \"token_output\": token_outputs,\n",
        "                                                            \"pooled_output\": pooled_output})\n",
        "    return output_spec\n",
        "  return model_fn"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gd-x0u5jHW5"
      },
      "source": [
        "#Input Functions\n",
        "def input_fn_builder(features, hidden_context, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "    num_examples = len(features)\n",
        "    hidden_shape = hidden_context.shape[-1]\n",
        "    d = tf.data.Dataset.from_tensor_slices({\"input_ids\": tf.constant(all_input_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"input_mask\": tf.constant(all_input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"segment_ids\": tf.constant(all_segment_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"label_ids\": tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "                                            \"hidden_context\": tf.constant(hidden_context, shape = [num_examples,hidden_shape], dtype = tf.float32),\n",
        "                                           })\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "  return input_fn"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpfcquOtjHRn"
      },
      "source": [
        "# Trainer Function\n",
        "\n",
        "Epochs = 10 # Number of Training Epochs \n",
        "\n",
        "def train(output_dir,input_fn):\n",
        "  CONFIG_FILE = \"multilingual_L-12_H-768_A-12/bert_config.json\"\n",
        "  INIT_CHECKPOINT = \"multilingual_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "\n",
        "  BATCH_SIZE = 28\n",
        "  LEARNING_RATE = 2e-5\n",
        "  NUM_TRAIN_EPOCHS = Epochs\n",
        "  WARMUP_PROPORTION = 0.1 # Warmup is a period of time where hte learning rate is small and gradually increases--usually helps training.\n",
        "  # Model configs\n",
        "  SAVE_CHECKPOINTS_STEPS = 6000\n",
        "  SAVE_SUMMARY_STEPS = 100\n",
        "  OUTPUT_DIR = output_dir\n",
        "  # Compute train and warmup steps from batch size\n",
        "  num_train_steps = int(len(input_fn) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "  print(num_train_steps)\n",
        "  run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR,save_summary_steps=SAVE_SUMMARY_STEPS,save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "  # Specify outpit directory and number of checkpoint steps to save\n",
        "  model_fn = model_fn_builder(bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "                              num_labels = 4, #number of unique labels\n",
        "                              init_checkpoint=INIT_CHECKPOINT,\n",
        "                              learning_rate=LEARNING_RATE,\n",
        "                              num_train_steps=num_train_steps,\n",
        "                              num_warmup_steps=num_warmup_steps,\n",
        "                              use_tpu=False,\n",
        "                              use_one_hot_embeddings=False)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params={\"batch_size\": BATCH_SIZE})\n",
        "  train_input_fn = bert.run_classifier.input_fn_builder(features=input_fn, seq_length=MAX_SEQ_LENGTH, is_training=True, drop_remainder=False)\n",
        "\n",
        "  print(f'Beginning Training!')\n",
        "  %timeit\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  return estimator"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC7sxM9VkOGw"
      },
      "source": [
        "# Function to get Train and Validation Proabilities for Ensemble\n",
        "\n",
        "\n",
        "#Evaluation Function for Train Data\n",
        "def evaluate_for_train(estimator,input_fn_for_train):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  test_input_fn = run_classifier.input_fn_builder(features=input_fn_for_train,seq_length=MAX_SEQ_LENGTH,is_training=False,drop_remainder=False)\n",
        "  \n",
        "  actual_labels = []\n",
        "  for i in test_data['label']:\n",
        "    actual_labels.append(i)\n",
        "    \n",
        "  res = estimator.predict(test_input_fn)\n",
        "  predicted_labels = []\n",
        "  probabilities = []\n",
        "  for i in res:\n",
        "    predicted_labels.append(i['labels'])\n",
        "    probabilities.append(i['probabilities'])\n",
        "  estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "  return actual_labels,predicted_labels,probabilities\n",
        "\n",
        "#Evaluation Function for Validation Data\n",
        "def evaluate_for_val_data(estimator,input_fn_for_test):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  test_input_fn = run_classifier.input_fn_builder(features=input_fn_for_test,seq_length=MAX_SEQ_LENGTH,is_training=False,drop_remainder=False)\n",
        "  \n",
        "  actual_labels = []\n",
        "  for i in test_data['label']:\n",
        "    actual_labels.append(i)\n",
        "\n",
        "  res = estimator.predict(test_input_fn)\n",
        "  predicted_labels = []\n",
        "  probabilities = []\n",
        "  for i in res:\n",
        "    predicted_labels.append(i['labels'])\n",
        "    probabilities.append(i['probabilities'])\n",
        "  estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "  return actual_labels,predicted_labels,probabilities\n",
        "\n",
        "#Evaluation Function for Test Data\n",
        "def evaluate_for_test_data(estimator,input_fn_for_test):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  test_input_fn = run_classifier.input_fn_builder(features=input_fn_for_test,seq_length=MAX_SEQ_LENGTH,is_training=False,drop_remainder=False)\n",
        "  \n",
        "  actual_labels = []\n",
        "  for i in test_data['label']:\n",
        "    actual_labels.append(i)\n",
        "  print('Len of Act Lab = ',len(actual_labels))\n",
        "  res = estimator.predict(test_input_fn)\n",
        "  predicted_labels = []\n",
        "  probabilities = []\n",
        "  l = 0\n",
        "  for i in res:\n",
        "    #print(l)\n",
        "    if (l == 1651):\n",
        "      break\n",
        "    predicted_labels.append(i['labels'])\n",
        "    probabilities.append(i['probabilities'])\n",
        "    l += 1\n",
        "  predicted_labels.append(predicted_labels[1650])\n",
        "  probabilities.append(probabilities[1650])\n",
        "  predicted_labels.append(predicted_labels[1650])\n",
        "  probabilities.append(probabilities[1650])\n",
        "  estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "  return actual_labels,predicted_labels,probabilities"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwLccjfZJwV6",
        "outputId": "45991b58-ad6c-458a-b1ac-9cdc909226b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-upbRud-s3-"
      },
      "source": [
        "# Use Link provided in ReadMe(Result).txt and download the FineTuned Weights and Load (Change paths accordingly)\r\n",
        "\r\n",
        "# Pretrained Model Loading\r\n",
        "\r\n",
        "# To Move the trained folder from drive to Local Machine\r\n",
        "# Mount Drive First\r\n",
        "!cp -a '/content/drive/MyDrive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/BERT_Coarse_Train' '/content/BERT_Training_Coarse' "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp5Uo-O9jHNc"
      },
      "source": [
        "# Train\n",
        "estimator = train('BERT_Training_Coarse', train_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kVV1NayJCVo"
      },
      "source": [
        "# Evaluate for Validation (Run while Creating Results for Validation Dataset Only)\r\n",
        "act_lab, pred_lab, test_prob = evaluate_for_val_data(estimator, test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQwEDqTjehI"
      },
      "source": [
        "# Evaluate for Test (Run while Creating Results for Test Dataset Only)\n",
        "act_lab, pred_lab, test_prob = evaluate_for_test_data(estimator, test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykaevts791GP"
      },
      "source": [
        "# Saving Probabilities\r\n",
        "test_prob = np.array(test_prob).reshape(len(test_prob),4)\r\n",
        "print(test_prob.shape)\r\n",
        "\r\n",
        "np.array(test_prob).dump(open('Test_Probs_Coarse_mBERT.npy', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}