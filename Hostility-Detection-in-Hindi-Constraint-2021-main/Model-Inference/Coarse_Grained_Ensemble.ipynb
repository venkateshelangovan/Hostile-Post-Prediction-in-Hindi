{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coarse Grained Ensemble.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95UzhBOzHUjx"
      },
      "source": [
        "# Code Objective:\n",
        "\n",
        "*   Ensemble from BERT and XLMRoberta Prediction Probabilities to Enhance Performance of Coarse Grained Evaluation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsXFEqjPINxA"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlW5QKbi2_IN"
      },
      "source": [
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, Add, Multiply, Average, Concatenate, Input, Subtract"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqHmJSIwIRQy"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmvhuUbo5_cv"
      },
      "source": [
        "path = '/content/'\n",
        "\n",
        "# Probability Data Loading\n",
        "x_test_1 = np.load(path + 'Test_Probs_Coarse_mBERT.npy', allow_pickle = True)\n",
        "x_test_1 = x_test_1[:,:2]\n",
        "x_test_2 = np.load(path + 'Test_Probs_Coarse_XLMR.npy', allow_pickle = True)\n",
        "\n",
        "print(\"X Test Prob BERT Size = {}\".format(x_test_1.shape))\n",
        "print(\"X Train Prob XLMR Size = {}\".format(x_test_2.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhX_VueOIaBw"
      },
      "source": [
        "# Ensemble Architecture (BERT and XLMRoberta)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCJN_30h54zt"
      },
      "source": [
        "# Input Placeholders\n",
        "input_1 = Input(shape = (2,))\n",
        "input_2 = Input(shape = (2,))\n",
        "\n",
        "# Ensemble Model Archirecture\n",
        "def Classifier_Top(input_1,input_2):\n",
        "    activation = 'tanh'\n",
        "    z1 = Dense(units = 50, activation = activation)(input_1)\n",
        "    z1 = Dropout(0.2)(z1)\n",
        "    z2 = Dense(units = 50, activation = activation)(input_2)\n",
        "    z2 = Dropout(0.2)(z2)\n",
        "    z = Concatenate()([z1,z2])\n",
        "    z = Dense(units = 30, activation = activation)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    z = Dense(units = 20, activation = activation)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    z = Dense(units = 10, activation = activation)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    z = Dense(units = 5, activation = activation)(z)\n",
        "    z = Dropout(0.2)(z)\n",
        "    output = Dense(units = 1, activation = 'sigmoid')(z)\n",
        "    model = Model(inputs = [input_1,input_2], outputs = output)\n",
        "    model.summary()\n",
        "    return model \n",
        "\n",
        "# Compile and Train Model\n",
        "def compile_and_train(model, num_epochs): \n",
        "    model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['acc']) \n",
        "    history = model.fit([x_train_1,x_train_2], y_train, batch_size=32, epochs=num_epochs, validation_split=0.2)\n",
        "    return history"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOvD3MJ_I0lw"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRMty4OQ8FZM"
      },
      "source": [
        "Epochs = 10                                     # Training Iteration Number\n",
        "Classifier = Classifier_Top(input_1,input_2)\n",
        "Classifier.load_weights(\"/content/Task_1_Best.h5\")\n",
        "Classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=['acc']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIR3Dpm9JmYA"
      },
      "source": [
        "# Test Result (Coarse Grained Evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKtzfRfD0buz"
      },
      "source": [
        "# Code for Changing \n",
        "\n",
        "mode = 'Testing'                   # Change Mode to 'Testing' while evaluation on Test Data      \n",
        "\n",
        "def pred_to_lab(y_pred_probs, mode):\n",
        "  labels = []\n",
        "  for i in y_pred_probs:\n",
        "    if i<0.5:\n",
        "      if mode == 'Num':\n",
        "        labels.append(0)\n",
        "      elif mode == 'Text':\n",
        "        labels.append('non-hostile')\n",
        "    else:\n",
        "      if mode == 'Num':\n",
        "        labels.append(1)\n",
        "      elif mode == 'Text':\n",
        "        labels.append('hostile')\n",
        "  if mode == 'Num':\n",
        "    return np.array(labels)\n",
        "  elif mode == 'Text':\n",
        "    return labels\n",
        "\n",
        "y_pred_probs = Classifier.predict([x_test_1,x_test_2])\n",
        "\n",
        "y_pred_lab = pred_to_lab(y_pred_probs, mode = 'Num')\n",
        "\n",
        "if (mode == 'Testing'):\n",
        "  y_pred_lab[1651] = 0\n",
        "  y_pred_lab[1652] = 0\n",
        "\n",
        "print(len(y_pred_lab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2JAXW3Angyk"
      },
      "source": [
        "np.array(y_pred_lab).dump(open('Test_Labels_Coarse.npy', 'wb'))"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}