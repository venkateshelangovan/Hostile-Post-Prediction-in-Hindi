{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "defame Result .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BzqiIMgJrq-w"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZKTUvZ-i9uS"
      },
      "source": [
        "SEED = 42\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install bert-tensorflow==1.0.1\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8daSeq_VaM0"
      },
      "source": [
        "# Training Data\r\n",
        "file = '/content/defamation_train.xlsx'\r\n",
        "train_df = pd.read_excel(file)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwnaXjWaWGz-"
      },
      "source": [
        "# Validation Data (Run only when Evaluation on Validation Data)\r\n",
        "file = '/content/Hostile_Validate.xlsx'\r\n",
        "test_df = pd.read_excel(file) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgO9kOSEan55"
      },
      "source": [
        "# Testing Data (Run only when Evaluation on Test Data)\r\n",
        "file = '/content/Hostile_Hindi_Test.xlsx'\r\n",
        "test_df = pd.read_excel(file, names = ['Unique ID','Post'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Bn7ACWjHG_"
      },
      "source": [
        "# Data Preparation into Pandas Dataframe for Model Input\n",
        "\n",
        "def get_data(a):\n",
        "  Unique_ID = list(a['Unique ID'])\n",
        "  sentence = list(a['Post'])\n",
        "  \n",
        "  label = []\n",
        "  for i in Unique_ID:\n",
        "      label.append(0)\n",
        "    \n",
        "  label = []\n",
        "\n",
        "  # Appending dummy labels\n",
        "  label = []\n",
        "  for i in Unique_ID:\n",
        "    label.append(0)\n",
        "\n",
        "  raw_data_train = {'UID':Unique_ID,'sentence': sentence, 'label': label}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['UID','sentence','label'])\n",
        "  return df\n",
        "\n",
        "train_data = get_data(train_df)\n",
        "test_data  = get_data(test_df)\n",
        "\n",
        "print(train_data[0:3])\n",
        "print(test_data[0:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYT3uHNMjHJ3"
      },
      "source": [
        "# Loading mBERT Model\n",
        "\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip\n",
        "!unzip multilingual_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCw7XyUpjHSd"
      },
      "source": [
        "label_list = [0,1]\n",
        "\n",
        "train_InputExamples = train_data.apply(lambda x: bert.run_classifier.InputExample(guid = x['UID'],\n",
        "                                                                                  text_a = x['sentence'],  \n",
        "                                                                                  label = x['label']), axis = 1)\n",
        "\n",
        "test_InputExamples = test_data.apply(lambda x: bert.run_classifier.InputExample(guid = x['UID'],\n",
        "                                                                                text_a = x['sentence'],  \n",
        "                                                                                label = x['label']), axis = 1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6-s5Q4jHYM"
      },
      "source": [
        "vocab_file = \"multilingual_L-12_H-768_A-12/vocab.txt\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n",
        "# Check Tokenizer\n",
        "print(tokenizer.tokenize(\"धीरे\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9inljAfjHex"
      },
      "source": [
        "# Convert train and test features to InputFeatures that BERT understands.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXQFANDRCxKZ"
      },
      "source": [
        "# Binary Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-0dlaxmjHdM"
      },
      "source": [
        "# Binary Classification Model\n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids, labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(config=bert_config,\n",
        "                                                 is_training=is_training,\n",
        "                                                 input_ids=input_ids,\n",
        "                                                 input_mask=input_mask,\n",
        "                                                 token_type_ids=segment_ids,\n",
        "                                                 use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "  #Sizes\n",
        "  output_layer = model.get_pooled_output()\n",
        "  pooled_output = model.get_pooled_output()\n",
        "  token_output = model.get_sequence_output()\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  #Trainable Parameters\n",
        "  output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "  output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)  # dropout = 0.1 \n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels,output_layer,token_output,pooled_output)\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate, num_train_steps, num_warmup_steps, use_tpu, use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels,hidden_context,token_outputs,pooled_output) = create_model(bert_config, \n",
        "                                                                                                         is_training, \n",
        "                                                                                                         input_ids, \n",
        "                                                                                                         input_mask, \n",
        "                                                                                                         segment_ids, \n",
        "                                                                                                         label_ids,\n",
        "                                                                                                         num_labels, \n",
        "                                                                                                         use_one_hot_embeddings)\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    output_spec = None\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        return {\"eval_accuracy\": accuracy, \"eval_loss\": loss}\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(mode=mode, \n",
        "                                               predictions={\"probabilities\": probabilities,\n",
        "                                                            \"labels\": predicted_labels, \n",
        "                                                            \"hidden_context\": hidden_context,\n",
        "                                                            \"token_output\": token_outputs,\n",
        "                                                            \"pooled_output\": pooled_output})\n",
        "    return output_spec\n",
        "  return model_fn"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gd-x0u5jHW5"
      },
      "source": [
        "#Input Functions\n",
        "def input_fn_builder(features, hidden_context, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "    num_examples = len(features)\n",
        "    hidden_shape = hidden_context.shape[-1]\n",
        "    d = tf.data.Dataset.from_tensor_slices({\"input_ids\": tf.constant(all_input_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"input_mask\": tf.constant(all_input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"segment_ids\": tf.constant(all_segment_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
        "                                            \"label_ids\": tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "                                            \"hidden_context\": tf.constant(hidden_context, shape = [num_examples,hidden_shape], dtype = tf.float32),\n",
        "                                           })\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "  return input_fn"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpfcquOtjHRn"
      },
      "source": [
        "# Trainer Function\n",
        "\n",
        "Epochs = 10 # Number of Training Epochs \n",
        "\n",
        "def train(output_dir,input_fn):\n",
        "  CONFIG_FILE = \"multilingual_L-12_H-768_A-12/bert_config.json\"\n",
        "  INIT_CHECKPOINT = \"multilingual_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "\n",
        "  BATCH_SIZE = 28\n",
        "  LEARNING_RATE = 2e-5\n",
        "  NUM_TRAIN_EPOCHS = Epochs\n",
        "  WARMUP_PROPORTION = 0.1 # Warmup is a period of time where hte learning rate is small and gradually increases--usually helps training.\n",
        "  # Model configs\n",
        "  SAVE_CHECKPOINTS_STEPS = 6000\n",
        "  SAVE_SUMMARY_STEPS = 100\n",
        "  OUTPUT_DIR = output_dir\n",
        "  # Compute train and warmup steps from batch size\n",
        "  num_train_steps = int(len(input_fn) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "  print(num_train_steps)\n",
        "  run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR,save_summary_steps=SAVE_SUMMARY_STEPS,save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "  # Specify outpit directory and number of checkpoint steps to save\n",
        "  model_fn = model_fn_builder(bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "                              num_labels = 2, #number of unique labels\n",
        "                              init_checkpoint=INIT_CHECKPOINT,\n",
        "                              learning_rate=LEARNING_RATE,\n",
        "                              num_train_steps=num_train_steps,\n",
        "                              num_warmup_steps=num_warmup_steps,\n",
        "                              use_tpu=False,\n",
        "                              use_one_hot_embeddings=False)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config, params={\"batch_size\": BATCH_SIZE})\n",
        "  train_input_fn = bert.run_classifier.input_fn_builder(features=input_fn, seq_length=MAX_SEQ_LENGTH, is_training=True, drop_remainder=False)\n",
        "\n",
        "  print(f'Beginning Training!')\n",
        "  %timeit\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  return estimator"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC7sxM9VkOGw"
      },
      "source": [
        "#Evaluation Function for Validation Data\n",
        "def evaluate(estimator,input_fn_for_test):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  test_input_fn = run_classifier.input_fn_builder(features=input_fn_for_test,seq_length=MAX_SEQ_LENGTH,is_training=False,drop_remainder=False)\n",
        "  \n",
        "  actual_labels = []\n",
        "  for i in test_data['label']:\n",
        "    actual_labels.append(i)\n",
        "  #print('Len of Act Lab = ',len(actual_labels))\n",
        "  res = estimator.predict(test_input_fn)\n",
        "  predicted_labels = []\n",
        "  probabilities = []\n",
        "  for i in res:\n",
        "    predicted_labels.append(i['labels'])\n",
        "    probabilities.append(i['probabilities'])\n",
        "  estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "  return actual_labels,predicted_labels,probabilities"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0w_s9a0XKky"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AR58rJk9g2u"
      },
      "source": [
        "# To Move the training folder from drive to local machine (Load Pretrained model from Link provided in the ReadMe and change the following path accordingly)\r\n",
        "!cp -a '/content/drive/My Drive/CONSTRAINT 2021 Projects (AAAI)/Hindi_Task/Weights/mBERT_Defamation_Binary' '/content/mBERT_Defamation_Binary'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp5Uo-O9jHNc"
      },
      "source": [
        "# Train\n",
        "estimator = train('mBERT_Defamation_Binary', train_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQwEDqTjehI"
      },
      "source": [
        "# Evaluate\n",
        "act_lab, pred_lab, test_probs = evaluate(estimator, test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I5UGQXxbKOf"
      },
      "source": [
        "# Saving Predicted Labels for Test Dataset or Validation Dataset\r\n",
        "np.array(pred_lab).dump(open('Pred_Defamation_Label.npy', 'wb'))"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}